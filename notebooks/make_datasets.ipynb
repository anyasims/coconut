{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "import itertools\n",
    "import os, sys\n",
    "import yaml\n",
    "import json\n",
    "import gc\n",
    "import argparse\n",
    "import functools\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy\n",
    "from transformers.models.llama.modeling_llama import LlamaDecoderLayer\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.append(os.path.abspath('/homes/80/anya/Documents/llm_tiny_ideas/coconut-outer/coconut'))\n",
    "from utils import Config, set_seed\n",
    "from coconut import Coconut\n",
    "from dataset import get_dataset, get_question_latent_dataset, get_cot_latent_dataset, MyCollator\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# rank = int(os.environ[\"RANK\"])\n",
    "# print(rank)\n",
    "# world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "# print(world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset: 100%|██████████| 100000/100000 [00:03<00:00, 29632.21it/s]\n",
      "Formatting questions: 100%|██████████| 100000/100000 [00:00<00:00, 225843.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "{'question': 'The final answer will be given after \"####\". The transitions are: {h->Z, I->h, e->I, K->V, V->Y, F->C, v->v, C->F, W->W, Z->e, Y->K}. Let\\'s think step-by-step and work out the symbol reached if we start at K and take 93 steps.', 'answer': 'K'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_transitions_size = 4\n",
    "max_transitions_size = 26\n",
    "min_num_steps = 4\n",
    "max_num_steps = 100\n",
    "all_symbols = [s for s in 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ']\n",
    "dataset_size = int(1e5)\n",
    "\n",
    "dataset_transition_dicts = []\n",
    "dataset_num_steps = []\n",
    "dataset_start_symbols = []\n",
    "dataset_answers = []\n",
    "for i in tqdm(range(dataset_size), desc='Generating dataset', total=dataset_size):\n",
    "    transitions_size = np.random.randint(min_transitions_size, max_transitions_size)\n",
    "    num_steps = np.random.randint(min_num_steps, max_num_steps)\n",
    "    from_symbols = np.random.choice(all_symbols, size=np.random.randint(min_transitions_size, max_transitions_size), replace=False)\n",
    "    to_symbols = from_symbols.copy()\n",
    "    np.random.shuffle(to_symbols)\n",
    "    transition_dict = dict(zip(from_symbols, to_symbols))\n",
    "    start_symbol = np.random.choice(from_symbols)\n",
    "    end_symbol = start_symbol.copy()\n",
    "    for _ in range(num_steps):\n",
    "        end_symbol = transition_dict[end_symbol]\n",
    "    dataset_transition_dicts.append(transition_dict)\n",
    "    dataset_num_steps.append(num_steps)\n",
    "    dataset_start_symbols.append(start_symbol)\n",
    "    dataset_answers.append(end_symbol)\n",
    "\n",
    "template = \"The final answer will be given after \\\"####\\\". The transitions are: <TRANSITIONS>. Let's think step-by-step and work out the symbol reached if we start at <START> and take <NUM_STEPS> steps.\"\n",
    "dataset_questions = []\n",
    "for i in tqdm(range(dataset_size), desc='Formatting questions', total=dataset_size):\n",
    "    dataset_transition_string = '{' + ', '.join([f'{k}->{v}' for k, v in dataset_transition_dicts[i].items()]) + '}'\n",
    "    question = template.replace('<TRANSITIONS>', dataset_transition_string).replace('<START>', dataset_start_symbols[i]).replace('<NUM_STEPS>', str(dataset_num_steps[i]))\n",
    "    dataset_questions.append(question)\n",
    "\n",
    "transitions_dataset = Dataset.from_dict({'question': dataset_questions, 'answer': dataset_answers})\n",
    "print(transitions_dataset)\n",
    "print(transitions_dataset[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-ary addition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 900000\n",
      "})\n",
      "{'question': 'Let\\'s work out the answer to 907 + 741 and give the answer after \"####\".', 'answer': '1648'} \n",
      "\n",
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 900000\n",
      "})\n",
      "{'question': 'Let\\'s work out the answer to 907 + 741 and give the answer after \"####\" starting from the rightmost digit.', 'answer': '8461'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_digits = 3\n",
    "all_number_pairs = np.arange(10**(2*num_digits-1), 10**(2*num_digits))\n",
    "np.random.shuffle(all_number_pairs)\n",
    "\n",
    "number1s = all_number_pairs // 10**num_digits\n",
    "number2s = all_number_pairs % 10**num_digits\n",
    "answers = number1s + number2s\n",
    "\n",
    "questions = [\n",
    "    f\"Let's work out the answer to {number1} + {number2} and give the answer after \\\"####\\\".\"\n",
    "    for number1, number2 in zip(number1s, number2s)\n",
    "]\n",
    "questions_reversed = [\n",
    "    f\"Let's work out the answer to {number1} + {number2} and give the answer after \\\"####\\\" starting from the rightmost digit.\"\n",
    "    for number1, number2 in zip(number1s, number2s)\n",
    "]\n",
    "answers = [str(answer) for answer in answers]\n",
    "answers_reversed = [str(answer)[::-1] for answer in answers]\n",
    "\n",
    "addition_dataset = Dataset.from_dict({'question': questions, 'answer': answers})\n",
    "addition_reversed_dataset = Dataset.from_dict({'question': questions_reversed, 'answer': answers_reversed})\n",
    "print(addition_dataset)\n",
    "print(addition_dataset[0], \"\\n\")\n",
    "print(addition_reversed_dataset)\n",
    "print(addition_reversed_dataset[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset:  83%|████████▎ | 165085/200000 [00:04<00:00, 38806.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Formatting questions: 100%|██████████| 100000/100000 [00:00<00:00, 282249.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "{'question': 'The final answer will be given after \"####\". The sequence is: [B, E, C, E, C, B, B, B, C, B, B, G, B, B, V, G, Y, E, V, V]. Let\\'s think step-by-step and find what letter comes after the 3rd last \"B\".', 'answer': 'G'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "min_num_hops = 1\n",
    "max_num_hops = 4\n",
    "sequence_length = 20\n",
    "alphabet_size = 6\n",
    "all_symbols = [s for s in 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ']\n",
    "all_symbols = [s for s in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']\n",
    "dataset_size = int(1e5)\n",
    "\n",
    "dataset_sequences = []\n",
    "dataset_letters = []\n",
    "dataset_num_hops = []\n",
    "dataset_answers = []\n",
    "i = 0\n",
    "for _ in tqdm(range(dataset_size*2), desc='Generating dataset', total=dataset_size*2):\n",
    "    if i >= dataset_size:\n",
    "        print(\"Dataset size reached.\")\n",
    "        break\n",
    "    alphabet = np.random.choice(all_symbols, size=alphabet_size, replace=False)\n",
    "    sequence = np.random.choice(alphabet, size=sequence_length, replace=True)\n",
    "    letter = np.random.choice(alphabet)\n",
    "    num_hops = np.random.randint(min_num_hops, max_num_hops)\n",
    "    letter_idxs = np.where(sequence == letter)[0]\n",
    "    if len(letter_idxs) <= num_hops or letter_idxs[-num_hops] == sequence_length-1:\n",
    "        continue\n",
    "    answer = sequence[letter_idxs[-num_hops]+1]\n",
    "    dataset_sequences.append(sequence)\n",
    "    dataset_letters.append(letter)\n",
    "    dataset_num_hops.append(num_hops)\n",
    "    dataset_answers.append(answer)\n",
    "    i += 1\n",
    "\n",
    "assert len(dataset_sequences) == dataset_size, f\"Dataset size is {len(dataset_sequences)}\"\n",
    "\n",
    "int_to_pos = {1: '', 2: ' 2nd', 3: ' 3rd', 4: ' 4th', 5: ' 5th', 6: ' 6th', 7: ' 7th', 8: ' 8th', 9: ' 9th', 10: ' 10th'}\n",
    "template = \"The final answer will be given after \\\"####\\\". The sequence is: <SEQUENCE>. Let's think step-by-step and find what letter comes after the<POS> last \\\"<LETTER>\\\".\"\n",
    "dataset_questions = []\n",
    "for i in tqdm(range(dataset_size), desc='Formatting questions', total=dataset_size):\n",
    "    sequence_as_string = \"[\" + ', '.join(dataset_sequences[i]) + \"]\"\n",
    "    question = template.replace('<SEQUENCE>', sequence_as_string).replace('<POS>', int_to_pos[dataset_num_hops[i]]).replace('<LETTER>', dataset_letters[i])\n",
    "    dataset_questions.append(question)\n",
    "\n",
    "phop_dataset = Dataset.from_dict({'question': dataset_questions, 'answer': dataset_answers})\n",
    "print(phop_dataset)\n",
    "print(phop_dataset[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i-gsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset: 100%|██████████| 1000/1000 [00:00<00:00, 5240.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 1000\n",
      "})\n",
      "{'question': 'J := 1, F := 3, U := J + J, L := U * 3, I := F + J, X := L, G := J - X, B := U, Z := B - L, W := B + I, W?', 'answer': 6} \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_symbols = [s for s in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']\n",
    "def generate_problem(depth=4, modulo=7):\n",
    "    \"\"\"\n",
    "    Generate one i-GSM style problem.\n",
    "    The problem is represented as a series of assignments (a DAG) with the following design:\n",
    "    - We start with a few constant assignments.\n",
    "    - Each subsequent assignment computes a new variable as a function (sum, subtraction, or multiplication)\n",
    "      of one to three previously defined variables and/or constants.\n",
    "    - All arithmetic is done modulo 7.\n",
    "    - Finally, a target variable is chosen and the problem is printed with its answer.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple (problem_str, answer) where problem_str is the full problem as a string,\n",
    "        and answer is the computed value (an integer between 0 and 6) for the target variable.\n",
    "    \"\"\"\n",
    "    # List to hold (var_name, expression, value) tuples.\n",
    "    assignments = []\n",
    "    \n",
    "    # For reproducibility, you could seed random here if desired.\n",
    "    \n",
    "    # Step 1. Create a few initial assignments with constant values.\n",
    "    num_initial = 2  # you can vary this number\n",
    "    for _ in range(num_initial):\n",
    "        var = np.random.choice(all_symbols)\n",
    "        # choose a constant between 0 and 6\n",
    "        const_val = np.random.randint(0, 6)\n",
    "        const_val_mod = const_val % modulo if modulo is not None else const_val\n",
    "        assignments.append((var, f\"{const_val}\", const_val_mod))\n",
    "    \n",
    "    # Step 2. Create additional assignments up to the desired depth.\n",
    "    # We ensure each new assignment only uses variables that were defined earlier.\n",
    "    num_assignments = depth * 2  # arbitrarily, total nodes ~ 2*depth\n",
    "    for i in range(num_assignments):\n",
    "        # Select a new variable name that is not already used.\n",
    "        var = np.random.choice(all_symbols)\n",
    "        while any(var == a[0] for a in assignments):\n",
    "            var = np.random.choice(all_symbols)\n",
    "            \n",
    "        # Choose an operation type: addition, subtraction, or multiplication.\n",
    "        op = np.random.choice([\"+\", \"-\", \"*\"])\n",
    "        \n",
    "        # Choose 1-3 operands randomly from previous assignments or a constant.\n",
    "        num_operands = np.random.randint(1, 3)\n",
    "        operands = []\n",
    "        operand_values = []\n",
    "        for _ in range(num_operands):\n",
    "            if assignments and np.random.random() < 0.7:\n",
    "                # choose an existing variable as operand\n",
    "                rand_idx = np.random.randint(0, len(assignments))\n",
    "                prev_var, _, prev_val = assignments[rand_idx]\n",
    "                operands.append(prev_var)\n",
    "                operand_values.append(prev_val)\n",
    "            else:\n",
    "                # or use a random constant\n",
    "                const_val = np.random.randint(0, 6)\n",
    "                operands.append(str(const_val))\n",
    "                operand_values.append(const_val)\n",
    "        \n",
    "        # Build the expression string.\n",
    "        expr_str = f\" {op} \".join(operands)\n",
    "        # Evaluate the expression modulo 7.\n",
    "        # Note: for subtraction, we apply left-to-right evaluation.\n",
    "        result = operand_values[0]\n",
    "        for val in operand_values[1:]:\n",
    "            if op == \"+\":\n",
    "                result = (result + val)\n",
    "            elif op == \"-\":\n",
    "                result = (result - val)\n",
    "            elif op == \"*\":\n",
    "                result = (result * val)\n",
    "            result = result % modulo if modulo is not None else result\n",
    "                \n",
    "        assignments.append((var, expr_str, result))\n",
    "    \n",
    "    # Step 3. Choose a target variable from the assignments (for instance, the last one)\n",
    "    target_var, _, target_val = assignments[-1]\n",
    "    \n",
    "    # Build the problem string:\n",
    "    # Each assignment is printed in the form \"var := expression.\"\n",
    "    # The final line is \"target_var?\" asking for its value.\n",
    "    problem_lines = []\n",
    "    for var, expr, _ in assignments:\n",
    "        problem_lines.append(f\"{var} := {expr}\")\n",
    "    problem_lines.append(f\"{target_var}?\")\n",
    "    \n",
    "    problem_str = \", \".join(problem_lines)\n",
    "    \n",
    "    return problem_str, target_val\n",
    "\n",
    "dataset_size = int(1e3)\n",
    "\n",
    "dataset_questions = []\n",
    "dataset_answers = []\n",
    "for i in tqdm(range(dataset_size), desc='Generating dataset', total=dataset_size):\n",
    "    q, a = generate_problem(depth=4, modulo=None)\n",
    "    dataset_questions.append(q)\n",
    "    dataset_answers.append(a)\n",
    "\n",
    "igsm_dataset = Dataset.from_dict({'question': dataset_questions, 'answer': dataset_answers})\n",
    "print(igsm_dataset)\n",
    "print(igsm_dataset[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# countdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_num = 1\n",
    "max_num = 100\n",
    "num_operands = 2\n",
    "max_num_extras = 1\n",
    "dataset_size = int(1e5)\n",
    "\n",
    "dataset_numbers = []\n",
    "dataset_target = []\n",
    "dataset_answer = []\n",
    "i = 0\n",
    "for _ in tqdm(range(dataset_size), desc='Generating dataset', total=dataset_size):\n",
    "    num_extras = np.random.randint(0, max_num_extras+1)\n",
    "    numbers = np.random.randint(min_num, max_num+1, size=num_operands+1)\n",
    "    extras = np.random.randint(min_num, max_num+1, size=num_extras)\n",
    "    operands = np.random.choice(['+', '-', '*', '/'], size=num_operands)\n",
    "    if all(op in ['+', '-'] for op in operands) or all(op in ['*', '/'] for op in operands):\n",
    "        pass\n",
    "    raise NotImplementedError\n",
    "\n",
    "assert len(dataset_sequences) == dataset_size, f\"Dataset size is {len(dataset_sequences)}\"\n",
    "\n",
    "template = f\"\"\"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.\n",
    "User: Using the numbers <NUMBERS>, create an equation that equals <TARGET>. You can use basic arithmetic operations (+, -, *, /) and each number can only be used once. Show your work and then return the final answer after \\\"####\\\", for example \\\"#### (1 + 2) / 3 \".\n",
    "Assistant: Let me solve this step by step.\n",
    "<think>\"\"\"\n",
    "\n",
    "dataset_questions = []\n",
    "for i in tqdm(range(dataset_size), desc='Formatting questions', total=dataset_size):\n",
    "    numbers_as_string = \"[\" + ', '.join(dataset_numbers[i]) + \"]\"\n",
    "    question = template.replace('<NUMBERS>', numbers_as_string).replace('<TARGET>', dataset_target[i])\n",
    "    dataset_questions.append(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def careful_repeat(tensor, num_repeats):\n",
    "    assert isinstance(tensor, torch.Tensor)\n",
    "    batch_size = tensor.shape[0]\n",
    "    if tensor.ndim == 1:\n",
    "        tensor = tensor.unsqueeze(1).repeat(1, num_repeats).reshape(batch_size*num_repeats, *tensor.shape[1:])\n",
    "    elif tensor.ndim == 2:\n",
    "        tensor = tensor.unsqueeze(1).repeat(1, num_repeats, 1).reshape(batch_size*num_repeats, *tensor.shape[1:])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid ndim: {tensor.ndim}\")\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.]])\n",
      "tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8.],\n",
      "        [5., 6., 7., 8.],\n",
      "        [5., 6., 7., 8.]])\n",
      "tensor([[2.5000, 2.5000, 2.5000],\n",
      "        [6.5000, 6.5000, 6.5000]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=torch.float32)\n",
    "y = careful_repeat(x, 3)\n",
    "z = y.mean(-1).reshape(2, 3)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coconut-1",
   "language": "python",
   "name": "coconut-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
