{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=5\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/80/anya/anaconda3/envs/coconut-1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from copy import copy\n",
    "import itertools\n",
    "import os, sys\n",
    "import yaml\n",
    "import json\n",
    "import gc\n",
    "import argparse\n",
    "import functools\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed.fsdp import FullyShardedDataParallel as FSDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.distributed.fsdp.wrap import transformer_auto_wrap_policy\n",
    "from transformers.models.llama.modeling_llama import LlamaDecoderLayer\n",
    "from datasets import Dataset\n",
    "\n",
    "sys.path.append(os.path.abspath('/homes/80/anya/Documents/llm_tiny_ideas/coconut-outer/coconut'))\n",
    "from utils import Config, set_seed\n",
    "from coconut import Coconut\n",
    "from dataset import get_dataset, get_question_latent_dataset, get_cot_latent_dataset, MyCollator\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "# rank = int(os.environ[\"RANK\"])\n",
    "# print(rank)\n",
    "# world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "# print(world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_transitions_size = 4\n",
    "max_transitions_size = 26\n",
    "min_num_steps = 4\n",
    "max_num_steps = 100\n",
    "all_symbols = [s for s in 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ']\n",
    "dataset_size = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating dataset: 100%|██████████| 100000/100000 [00:03<00:00, 30594.74it/s]\n",
      "Formatting questions: 100%|██████████| 100000/100000 [00:00<00:00, 221440.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 100000\n",
      "})\n",
      "{'question': 'The final answer will be given after \"####\". The transitions are: {n->b, b->n, J->J, y->y}. Let\\'s think step-by-step and work out the symbol reached if we start at n and take 76 steps.', 'answer': 'n'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_transition_dicts = []\n",
    "dataset_num_steps = []\n",
    "dataset_start_symbols = []\n",
    "dataset_answers = []\n",
    "for i in tqdm(range(dataset_size), desc='Generating dataset', total=dataset_size):\n",
    "    transitions_size = np.random.randint(min_transitions_size, max_transitions_size)\n",
    "    num_steps = np.random.randint(min_num_steps, max_num_steps)\n",
    "    from_symbols = np.random.choice(all_symbols, size=np.random.randint(min_transitions_size, max_transitions_size), replace=False)\n",
    "    to_symbols = from_symbols.copy()\n",
    "    np.random.shuffle(to_symbols)\n",
    "    transition_dict = dict(zip(from_symbols, to_symbols))\n",
    "    start_symbol = np.random.choice(from_symbols)\n",
    "    end_symbol = start_symbol.copy()\n",
    "    for _ in range(num_steps):\n",
    "        end_symbol = transition_dict[end_symbol]\n",
    "    dataset_transition_dicts.append(transition_dict)\n",
    "    dataset_num_steps.append(num_steps)\n",
    "    dataset_start_symbols.append(start_symbol)\n",
    "    dataset_answers.append(end_symbol)\n",
    "\n",
    "template = \"The final answer will be given after \\\"####\\\". The transitions are: <TRANSITIONS>. Let's think step-by-step and work out the symbol reached if we start at <START> and take <NUM_STEPS> steps.\"\n",
    "dataset_questions = []\n",
    "for i in tqdm(range(dataset_size), desc='Formatting questions', total=dataset_size):\n",
    "    dataset_transition_string = '{' + ', '.join([f'{k}->{v}' for k, v in dataset_transition_dicts[i].items()]) + '}'\n",
    "    question = template.replace('<TRANSITIONS>', dataset_transition_string).replace('<START>', dataset_start_symbols[i]).replace('<NUM_STEPS>', str(dataset_num_steps[i]))\n",
    "    dataset_questions.append(question)\n",
    "\n",
    "transitions_dataset = Dataset.from_dict({'question': dataset_questions, 'answer': dataset_answers})\n",
    "print(dataset)\n",
    "print(dataset[0], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-ary addition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 900000\n",
      "})\n",
      "{'question': 'Let\\'s work out the answer to 355 + 484 and give the answer after \"####\".', 'answer': '839'} \n",
      "\n",
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 900000\n",
      "})\n",
      "{'question': 'Let\\'s work out the answer to 355 + 484 and give the answer after \"####\" starting from the rightmost digit.', 'answer': '938'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_digits = 3\n",
    "all_number_pairs = np.arange(10**(2*num_digits-1), 10**(2*num_digits))\n",
    "np.random.shuffle(all_number_pairs)\n",
    "\n",
    "number1s = all_number_pairs // 10**num_digits\n",
    "number2s = all_number_pairs % 10**num_digits\n",
    "answers = number1s + number2s\n",
    "\n",
    "questions = [\n",
    "    f\"Let's work out the answer to {number1} + {number2} and give the answer after \\\"####\\\".\"\n",
    "    for number1, number2 in zip(number1s, number2s)\n",
    "]\n",
    "questions_reversed = [\n",
    "    f\"Let's work out the answer to {number1} + {number2} and give the answer after \\\"####\\\" starting from the rightmost digit.\"\n",
    "    for number1, number2 in zip(number1s, number2s)\n",
    "]\n",
    "answers = [str(answer) for answer in answers]\n",
    "answers_reversed = [str(answer)[::-1] for answer in answers]\n",
    "\n",
    "addition_dataset = Dataset.from_dict({'question': questions, 'answer': answers})\n",
    "addition_reversed_dataset = Dataset.from_dict({'question': questions_reversed, 'answer': answers_reversed})\n",
    "print(addition_dataset)\n",
    "print(addition_dataset[0], \"\\n\")\n",
    "print(addition_reversed_dataset)\n",
    "print(addition_reversed_dataset[0], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coconut-1",
   "language": "python",
   "name": "coconut-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
